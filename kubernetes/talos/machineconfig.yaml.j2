---
version: v1alpha1
debug: false
persist: true
machine:
  type: controlplane
  token: {{ trustdinfo.token }}

  ca:
    crt: {{ certs.os.crt }}
    key: {{ certs.os.key }}

  kubelet:
    # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
    image: ghcr.io/siderolabs/kubelet:v1.35.0
    defaultRuntimeSeccompProfileEnabled: true
    disableManifestsDirectory: true
    extraConfig:
      serializeImagePulls: false
    nodeIP:
      validSubnets:
        - {{ hostvars[groups['k8s'][0]].management_cidr }}

  network:
    nameservers:
      - {{ hostvars[groups['k8s'][0]].ip_addr | ansible.utils.nthhost(1) }}

  install:
    # renovate: datasource=docker depName=ghcr.io/siderolabs/installer
    image: factory.talos.dev/metal-installer/{{ schematic }}:v1.11.5

  features:
    rbac: true
    stableHostname: true
    apidCheckExtKeyUsage: true
    diskQuotaSupport: true
    kubePrism:
      enabled: true
      port: 7445
    hostDNS:
      enabled: true
      forwardKubeDNSToHost: true
      resolveMemberNames: true
    kubernetesTalosAPIAccess:
      allowedKubernetesNamespaces:
        - actions-runner-system
        - system-upgrade
      allowedRoles:
        - os:admin
      enabled: true

  files:
    - op: create
      path: /etc/cri/conf.d/20-customization.part
      content: |
        [plugins."io.containerd.cri.v1.images"]
          discard_unpacked_layers = false
        [plugins."io.containerd.cri.v1.runtime"]
          cdi_spec_dirs = ["/var/cdi/static", "/var/cdi/dynamic"]
          device_ownership_from_security_context = true
    - op: overwrite
      path: /etc/nfsmount.conf
      permissions: 0o644
      content: |
        [ NFSMount_Global_Options ]
        nfsvers=4.2
        hard=True
        nconnect=16
        noatime=True

  sysctls:
    fs.inotify.max_user_instances: "8192"
    fs.inotify.max_user_watches: "1048576"
    net.core.default_qdisc: fq
    net.core.rmem_max: "67108864"
    net.core.wmem_max: "67108864"
    net.ipv4.neigh.default.gc_thresh1: "4096"
    net.ipv4.neigh.default.gc_thresh2: "8192"
    net.ipv4.neigh.default.gc_thresh3: "16384"
    net.ipv4.ping_group_range: 0 2147483647
    net.ipv4.tcp_congestion_control: bbr
    net.ipv4.tcp_fastopen: "3"
    net.ipv4.tcp_mtu_probing: "1"
    net.ipv4.tcp_notsent_lowat: "131072"
    net.ipv4.tcp_rmem: 4096 87380 33554432
    net.ipv4.tcp_slow_start_after_idle: "0"
    net.ipv4.tcp_window_scaling: "1"
    net.ipv4.tcp_wmem: 4096 65536 33554432
    sunrpc.tcp_max_slot_table_entries: "128"
    sunrpc.tcp_slot_table_entries: "128"
    user.max_user_namespaces: "11255"
    vm.nr_hugepages: "1024"

  kernel:
    modules:
      - name: nbd

cluster:
  id: {{ cluster.id }}
  secret: {{ cluster.secret }}
  controlPlane:
    endpoint: https://{{ hostvars[groups['k8s'][0]].cluster_endpoint_addr }}:6443
  clusterName: main
  token: {{ secrets.bootstraptoken }}
  secretboxEncryptionSecret: {{ secrets.secretboxencryptionsecret }}
  ca:
    crt: {{ certs.k8s.crt }}
    key: {{ certs.k8s.key }}
  aggregatorCA:
    crt: {{ certs.k8saggregator.crt }}
    key: {{ certs.k8saggregator.key }}
  serviceAccount:
    key: {{ certs.k8sserviceaccount.key }}

  network:
    dnsDomain: cluster.local
    podSubnets:
      - 10.42.0.0/16
    serviceSubnets:
      - 10.96.0.0/12
    cni:
      name: none

  apiServer:
    # renovate: datasource=docker depName=registry.k8s.io/kube-apiserver
    image: registry.k8s.io/kube-apiserver:v1.35.0
    certSANs:
      - {{ hostvars[groups['k8s'][0]].cluster_endpoint }}
    disablePodSecurityPolicy: true
    auditPolicy:
      apiVersion: audit.k8s.io/v1
      kind: Policy
      rules:
        - level: Metadata
    extraArgs:
      enable-aggregator-routing: "true"
      feature-gates: MutatingAdmissionPolicy=true
      runtime-config: admissionregistration.k8s.io/v1beta1=true
      oidc-issuer-url: "https://accounts.google.com"
      oidc-client-id: "{{ google_oauth_client_id }}"
      oidc-username-claim: "email"
      oidc-username-prefix: "-"

  controllerManager:
    # renovate: datasource=docker depName=registry.k8s.io/kube-controller-manager
    image: registry.k8s.io/kube-controller-manager:v1.35.0
    extraArgs:
      bind-address: 0.0.0.0

  proxy:
    disabled: true
    # renovate: datasource=docker depName=registry.k8s.io/kube-proxy
    image: registry.k8s.io/kube-proxy:v1.35.0

  scheduler:
    # renovate: datasource=docker depName=registry.k8s.io/kube-scheduler
    image: registry.k8s.io/kube-scheduler:v1.35.0
    extraArgs:
      bind-address: 0.0.0.0
    config:
      apiVersion: kubescheduler.config.k8s.io/v1
      kind: KubeSchedulerConfiguration
      profiles:
        - schedulerName: default-scheduler
          plugins:
            score:
              disabled:
                - name: ImageLocality
          pluginConfig:
            - name: PodTopologySpread
              args:
                defaultingType: List
                defaultConstraints:
                  - maxSkew: 1
                    topologyKey: kubernetes.io/hostname
                    whenUnsatisfiable: ScheduleAnyway

  etcd:
    ca:
      crt: {{ certs.etcd.crt }}
      key: {{ certs.etcd.key }}
    advertisedSubnets:
      - {{ hostvars[groups['k8s'][0]].management_cidr }}
    extraArgs:
      listen-metrics-urls: http://0.0.0.0:2381

  extraManifests: []
  inlineManifests: []

  coreDNS:
    disabled: true

  discovery:
    enabled: true
    registries:
      kubernetes:
        disabled: true
      service:
        disabled: false

  allowSchedulingOnControlPlanes: true
---
apiVersion: v1alpha1
kind: WatchdogTimerConfig
device: /dev/watchdog0
timeout: 5m
