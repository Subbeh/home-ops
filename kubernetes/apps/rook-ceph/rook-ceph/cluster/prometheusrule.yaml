---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/monitoring.coreos.com/prometheusrule_v1.json
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ceph-diagnostic-alerts
  namespace: rook-ceph
spec:
  groups:
    - name: ceph.disk-io
      interval: 30s
      rules:
        # Detect disk I/O saturation on RBD devices
        - alert: CephRBDDiskSaturation
          expr: |
            rate(node_disk_io_time_seconds_total{device=~"rbd.*"}[2m]) > 0.7
          for: 2m
          annotations:
            summary: "Ceph RBD disk {{ $labels.device }} on {{ $labels.instance }} >70% saturated"
            description: "Disk utilization {{ $value | humanizePercentage }} may cause OSD delays"
          labels:
            severity: warning

        # Detect high disk read rates indicating scrubbing or backup activity
        - alert: CephDiskReadSpike
          expr: |
            rate(node_disk_read_bytes_total{device=~"rbd.*|nvme.*"}[1m]) > 10485760
          for: 3m
          annotations:
            summary: "High disk read rate on {{ $labels.device }} ({{ $labels.instance }})"
            description: "Reading {{ $value | humanize }}B/s - possible scrubbing or backup activity"
          labels:
            severity: info

    - name: ceph.load-average
      interval: 30s
      rules:
        # Detect high load average indicating I/O wait
        - alert: NodeHighLoadAverage
          expr: |
            node_load1 > 8
          for: 2m
          annotations:
            summary: "High load average on {{ $labels.instance }}"
            description: "Load average {{ $value }} - likely I/O wait or CPU saturation"
          labels:
            severity: warning

        # Critical load indicating severe I/O starvation
        - alert: NodeCriticalLoadAverage
          expr: |
            node_load1 > 15
          for: 1m
          annotations:
            summary: "CRITICAL load average on {{ $labels.instance }}"
            description: "Load {{ $value }} may cause application delays and timeouts"
          labels:
            severity: critical

    - name: ceph.scrubbing
      interval: 60s
      rules:
        # Info alert when scrubbing is active (expected during 2-6 AM)
        - alert: CephScrubbingActive
          expr: |
            ceph_pg_scrubbing > 3
          for: 10m
          annotations:
            summary: "Multiple PGs scrubbing simultaneously"
            description: "{{ $value }} PGs scrubbing - monitor disk I/O and load average"
          labels:
            severity: info
